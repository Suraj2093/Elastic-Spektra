AWSTemplateFormatVersion: "2010-09-09"
Transform: AWS::Serverless-2016-10-31
Description: This template creates logging buckets for S3 access logs and ELB access logs, replicated to a central log-archive account.
             
Parameters: 
    LoggingAccountId:
      Type: 'String'
      Description: AWS Account Id where the elastic-log-ingestion-control-tower serverless application is deployed.
      AllowedPattern: "[0-9]{12}"
      
    LoggingRegion:
      Type: 'String'
      Description: >
        Specify the AWS Region where you have deployed the elastic-log-ingestion-control-tower serverless application.
        Example: us-east-1 (If the elastic-log-ingestion-control-tower serverless application is deployed in the North Virginia Region).
        
    ElasticCloudID:
      Type: String
      Description: The unique Cloud ID for your Elasticsearch cluster deployment.
      NoEcho: true

    ElasticAPIKey:
      Type: String
      Description: The RESTful API key providing access to deployment CRUD actions.
      NoEcho: true
      
    IngestKinesisLogs:
      Type: String
      Default: "No"
      AllowedValues:
      - "Yes"
      - "No"
      Description: "Do you want to ingest Kinesis data streams to the Elastic Cloud? (Choose 'Yes' or 'No'). If yes, make sure you have Kinesis data stream already created."

    KinesisDataStreamArn:
      Type: CommaDelimitedList
      Default: ""
      Description: "Comma delimited list of Kinesis Data Stream ARNs (Provide the value only if you want to ingest the Kinesis data streams to the Elastic Cloud)"
      
    IngestCloudWatchLogs:
      Type: String
      Default: "No"
      AllowedValues:
      - "Yes"
      - "No"
      Description: "Do you want to ingest CloudWatch Log Group logs to the Elastic Cloud? (Choose 'Yes' or 'No'). If yes, provide log group ARNs."

    CloudWatchLogGroupArns:
      Type: CommaDelimitedList
      Default: ""
      Description: "Comma delimited list of CloudWatch Log Group ARNs (Provide the value only if you want to ingest the CloudWatch Log Group logs to the Elastic Cloud)"
      
    DeployInVPC:
      Type: String
      Description: >
        'If you want to ingest either Kinesis data Streams or the CloudWatch logs to Elastic Cloud, an Elastic Serverless Forwarder will be deployed. Do you want to deploy this Elastic Serverless Forwarder in a VPC? (Enter "Yes" or "No").
        Note: If Yes, make sure a VPC is already been created in the region before deploying this CFT.' 
      Default: 'No'
      AllowedValues: ['Yes', 'No']

    VPCId:
      Type: String
      Default: ""
      Description: 'Enter the VPC ID in which you want to deploy the Elastic Serverless Forwarder. Provide the value only if you want to deploy the Elastic Serverless Forwarder in the VPC'

    SubnetIds:
      Type: CommaDelimitedList
      Default: ""
      Description: 'Enter the Subnet IDs (comma-separated) for the Elastic Serverless Forwarder. Provide the value only if you want to deploy the Elastic Serverless Forwarder in the VPC'
      ConstraintDescription: 'Please enter a valid list of Subnet IDs.'
    
    RouteTableIds:
      Type: CommaDelimitedList
      Default: ""
      Description: 'Specify the IDs of the route tables to be updated for the S3 bucket Gateway VPC Endpoint. Provide values only if deploying the Elastic serverless forwarder in a VPC.'
      ConstraintDescription: 'Please enter valid Route Table IDs.'
      
    EnableKinesisFirehoseIngestion:
      Type: String
      Default: "No"
      AllowedValues:
        - "Yes"
        - "No"
      Description: "Specify whether you want to ingest logs to Elastic Cloud using Amazon Kinesis Firehose Delivery Stream. Choose 'Yes' to enable ingestion via Kinesis Firehose, or 'No' to ingest logs via a different method."
    
    ElasticEndpointURL:
      Type: String
      Default: ""
      Description: "Specify the endpoint URL of your Elastic deployment. This is the URL where your Elastic services are hosted. Note: Ensure this value is entered accurately to enable proper integration with your Elastic deployment."

    IngestEC2Logs:
      Type: String
      Default: "No"
      AllowedValues:
      - "Yes"
      - "No"
      Description: "Do you want to ingest EC2 logs to the Elastic Cloud? (Choose 'Yes' or 'No')."
      
    KibanaURL:
      Type: String
      Default: ''
      Description: >-
        If you want to ingest EC2 logs to Elastic Cloud, then provide the Kibana
        URL in this section.
    
    ElasticsearchUsername:
      Type: String
      Default: ''
      Description: "Specify the username for accessing the Elasticsearch deployment."
      
    ElasticsearchPassword:
      Type: String
      Default: ''
      Description: "Specify the password for accessing the Elasticsearch deployment."
      NoEcho: true
      
    ElasticSearchDeploymentID:
      Type: String
      Default: ''
      Description: "Specify the unique Deployment ID associated with your Elasticsearch deployment."
      
    DeploymentVersion:
      Type: String
      Default: ''
      Description: "Specify the version of the Elasticsearch deployment."
    
Conditions:
  ShouldIngestKinesisDataStream: !Equals [!Ref IngestKinesisLogs, "Yes"]
  ShouldIngestCloudWatchLogs: !Equals [!Ref IngestCloudWatchLogs, "Yes"]
  ShouldDeployElasticForwarderInVPC: !Equals [!Ref DeployInVPC, "Yes"]
  ShouldDeployElasticServerlessForwarder: !Or
    - !Equals [!Ref IngestKinesisLogs, "Yes"]
    - !Equals [!Ref IngestCloudWatchLogs, "Yes"]
  ShouldDeployVPCResource: !And
    - !Equals [!Ref DeployInVPC, "Yes"]
    - Condition: ShouldDeployElasticServerlessForwarder
  ShouldIngestLogsViaKinesisFireHose: !Equals [!Ref EnableKinesisFirehoseIngestion, "Yes"]
  ShouldIngestEC2InstanceLogs: !Equals [!Ref IngestEC2Logs, "Yes"]
    
Metadata:
  AWS::CloudFormation::Interface:
    ParameterGroups:
    - Label:
        default: Log Archive Account Details
      Parameters:
      - LoggingAccountId
      - LoggingRegion
    - Label:
        default: Elastic Cluster Deployment Details
      Parameters:
      - ElasticCloudID
      - ElasticAPIKey
    - Label:
        default: Ingest kinesis data stream (Optional)
      Parameters:
      - IngestKinesisLogs
      - KinesisDataStreamArn
    - Label:
        default: Ingest CloudWatch LogGroup Logs (Optional)
      Parameters:
      - IngestCloudWatchLogs
      - CloudWatchLogGroupArns
    - Label:
        default: Deploy Elastic Forwarder in a VPC (Optional)
      Parameters:
      - DeployInVPC
      - VPCId
      - SubnetIds
      - RouteTableIds
    - Label:
        default: Ingest EC2 Instance Logs (Optional)
      Parameters:
      - IngestEC2Logs
      - KibanaURL
      - ElasticsearchUsername
      - ElasticsearchPassword
      - ElasticSearchDeploymentID
      - DeploymentVersion
    - Label:
        default: Ingest Logs Via AWS KinesisFireHose delivery stream (Optional)
      Parameters:
      - EnableKinesisFirehoseIngestion
      - ElasticEndpointURL
    ParameterLabels:
      ElasticCloudID:
        default: Elastic Cloud ID
      ElasticAPIKey:
        default: Elastic API Key
      LoggingAccountId:
        default: Account ID
      LoggingRegion:
        default: Logging Region
      IngestKinesisLogs:
        default: Ingest Kinesis Logs
      KinesisDataStreamArn:
        default: Kinesis Data Stream ARN
      IngestCloudWatchLogs:
        default: Ingest CloudWatch Logs
      CloudWatchLogGroupArns:
        default: CloudWatch LogGroup ARNs
      DeployInVPC:
        default: Deploy Elastic Serverless Forwarder in a VPC
      VPCId:
        default: VPC ID
      SubnetIds:
        default: Subnet IDs
      RouteTableIds:
        Default: Route Table IDs
      ElasticEndpointURL:
        Default: Elasticsearch Endpoint URL
      IngestEC2Logs:
        default: Ingest EC2 Logs
      KibanaURL:
        Default: Kibana URL
      ElasticsearchUsername:
        Default: Elasticsearch Username
      ElasticsearchPassword:
        Default: Elasticsearch Password
      ElasticSearchDeploymentID:
        Default: ElasticSearch DeploymentID
      DeploymentVersion:
        Default: Deployment Version
      EnableKinesisFirehoseIngestion:
        default: Enable Kinesis Firehose Ingestion

Mappings:
  VPCServiceName:
    af-south-1: 
      service: com.amazonaws.vpce.us-east-1.vpce-svc-0e42e1e06ed010238
    ap-east-1:
      service: com.amazonaws.vpce.ap-east-1.vpce-svc-0f96fbfaf55558d5c
    ap-northeast-1:
      service: com.amazonaws.vpce.ap-northeast-1.vpce-svc-0e1046d7b48d5cf5f
    ap-northeast-2:
      service: com.amazonaws.vpce.ap-northeast-2.vpce-svc-0d90cf62dae682b84
    ap-south-1:
      service: com.amazonaws.vpce.ap-south-1.vpce-svc-0e9c1ae5caa269d1b
    ap-southeast-1:
      service: com.amazonaws.vpce.ap-southeast-1.vpce-svc-0cbc6cb9bdb683a95
    ap-southeast-2:
      service: com.amazonaws.vpce.ap-southeast-2.vpce-svc-0cde7432c1436ef13
    ca-central-1:
      service: com.amazonaws.vpce.ca-central-1.vpce-svc-0d3e69dd6dd336c28
    eu-central-1:
      service: com.amazonaws.vpce.eu-central-1.vpce-svc-081b2960e915a0861
    eu-south-1:
      service: com.amazonaws.vpce.eu-south-1.vpce-svc-03d8fc8a66a755237
    eu-north-1:
      service: com.amazonaws.vpce.eu-north-1.vpce-svc-05915fc851f802294
    eu-west-1:
      service: com.amazonaws.vpce.eu-west-1.vpce-svc-01f2afe87944eb12b
    eu-west-2:
      service: com.amazonaws.vpce.eu-west-2.vpce-svc-0e42a2c194c97a1d0
    eu-west-3:
      service: com.amazonaws.vpce.eu-west-3.vpce-svc-0d6912d10db9693d1
    me-south-1:
      service: com.amazonaws.vpce.me-south-1.vpce-svc-0381de3eb670dcb48
    sa-east-1:
      service: com.amazonaws.vpce.sa-east-1.vpce-svc-0b2dbce7e04dae763
    us-east-1: 
      service: com.amazonaws.vpce.us-east-1.vpce-svc-0e42e1e06ed010238
    us-east-2:
      service: com.amazonaws.vpce.us-east-2.vpce-svc-02d187d2849ffb478
    us-west-1:
      service: com.amazonaws.vpce.us-west-1.vpce-svc-00def4a16a26cb1b4
    us-west-2:
      service: com.amazonaws.vpce.us-west-2.vpce-svc-0e69febae1fb91870
      
  PrivateHostedZoneDNSName:
    af-south-1:
      HostedZone: af-south-1.aws.found.io
    ap-east-1:
      HostedZone: ap-east-1.aws.found.io
    ap-northeast-1:
      HostedZone: ap-northeast-1.aws.found.io
    ap-northeast-2:
      HostedZone: ap-northeast-2.aws.found.io
    ap-south-1:
      HostedZone: ap-south-1.aws.found.io
    ap-southeast-1:
      HostedZone: ap-southeast-1.aws.found.io
    ap-southeast-2:
      HostedZone: ap-southeast-2.aws.found.io
    ca-central-1:
      HostedZone: ca-central-1.aws.found.io
    eu-central-1:
      HostedZone: eu-central-1.aws.found.io
    eu-south-1:
      HostedZone: eu-south-1.aws.found.io
    eu-north-1:
      HostedZone: eu-north-1.aws.found.io
    eu-west-1:
      HostedZone: eu-west-1.aws.found.io
    eu-west-2:
      HostedZone: eu-west-2.aws.found.io
    eu-west-3:
      HostedZone: eu-west-3.aws.found.io
    me-south-1:
      HostedZone: me-south-1.aws.found.io
    sa-east-1:
      HostedZone: sa-east-1.aws.found.io
    us-east-1: 
      HostedZone: us-east-1.aws.found.io
    us-east-2:
      HostedZone: us-east-2.aws.found.io
    us-west-1:
      HostedZone: us-west-1.aws.found.io
    us-west-2:
      HostedZone: us-west-2.aws.found.io   

  AMIID:
    af-south-1: 
      ami: ami-05759acc7d8973892
    ap-east-1:
      ami: ami-03490b1b7425e5fe3
    ap-northeast-1:
      ami: ami-09a81b370b76de6a2
    ap-northeast-2:
      ami: ami-086cae3329a3f7d75
    ap-south-1:
      ami: ami-0287a05f0ef0e9d9a
    ap-southeast-1:
      ami: ami-078c1149d8ad719a7
    ap-southeast-2:
      ami: ami-0df4b2961410d4cff
    ca-central-1:
      ami: ami-06873c81b882339ac
    eu-central-1:
      ami: ami-06dd92ecc74fdfb36
    eu-south-1:
      ami: ami-0b03947fd0ce0eed2
    eu-north-1:
      ami: ami-0fe8bec493a81c7da
    eu-west-1:
      ami: ami-0694d931cee176e7d
    eu-west-2:
      ami: ami-0505148b3591e4c07
    eu-west-3:
      ami: ami-00983e8a26e4c9bd9
    me-south-1: 
      ami: ami-0f8d2a6080634ee69
    sa-east-1: 
      ami: ami-0b6c2d49148000cd5
    us-east-1: 
      ami: ami-0fc5d935ebf8bc3bc
    us-east-2:
      ami: ami-0e83be366243f524a
    us-west-1: 
      ami: ami-0cbd40f694b804622
    us-west-2:
      ami: ami-0efcece6bed30fd98 

Resources:
  ElasticSecret:
    Type: AWS::SecretsManager::Secret
    DependsOn: ElasticSSMSecretEncryptionKey
    Condition: ShouldDeployElasticServerlessForwarder
    Properties:
      Name: !Sub "ElasticCloudSecret-${AWS::StackName}"
      KmsKeyId: !Ref ElasticSSMSecretEncryptionKey
      SecretString: !Sub |
        {
          "ElasticCloudID": "${ElasticCloudID}",
          "APIKey": "${ElasticAPIKey}"
        }
        
  ElasticSSMSecretEncryptionKey:     # Create a KMS Key to encrypt the secrets in AWS SSM store
    Type: AWS::KMS::Key
    Condition: ShouldDeployElasticServerlessForwarder
    Properties:
      Description: Encrypt the secrets stored in the SSM Store.
      Enabled: true
      EnableKeyRotation: true
      KeyUsage: ENCRYPT_DECRYPT
      PendingWindowInDays: 7
      KeyPolicy:
        Version: 2012-10-17
        Id: sqs-use
        Statement:
          - Sid: Key Admin Usage
            Effect: Allow
            Principal:
              AWS: !Sub "arn:aws:iam::${AWS::AccountId}:root"
            Action: 
              - 'kms:*'
            Resource: '*'
          - Sid: Elastic-Lambda-Permission
            Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action:
              - 'kms:GenerateDataKey*'
              - 'kms:Decrypt'
            Resource: '*'

  ElasticSSMSecretKMSKeyAlias:
    Type: AWS::KMS::Alias
    Condition: ShouldDeployElasticServerlessForwarder
    Properties:
      AliasName: alias/ElasticHelperSSMSecretEncryptionKey
      TargetKeyId: !Ref ElasticSSMSecretEncryptionKey
        
  S3ReplicationRole:        #Role for S3 service to replicated objects to Log Archive S3 Bucket
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument: 
        Version: "2012-10-17"
        Statement: 
          - 
            Action: 
              - "sts:AssumeRole"
            Effect: "Allow"
            Principal: 
              Service: 
                - "s3.amazonaws.com"
      Path: "/"
      RoleName: "elastic-AWS-S3-Replication"

  S3ReplicationRolePolicy: 
    Type: "AWS::IAM::ManagedPolicy"
    Properties: 
      PolicyDocument: 
        Version: "2012-10-17"
        Statement: 
          - 
            Action:
              - s3:ListBucket
              - s3:GetBucketLocation
              - s3:GetReplicationConfiguration
              - s3:GetObjectVersionForReplication
              - s3:GetObjectVersion
              - s3:GetObjectVersionAcl
              - s3:GetObjectVersionTagging
              - s3:GetObjectRetention
              - s3:GetObjectLegalHold
            Effect: "Allow"
            Resource:
              - arn:aws:s3:::elastic-central-elb-access-logs-*/*
              - arn:aws:s3:::elastic-central-waf-access-logs-*/*
              - arn:aws:s3:::elastic-central-emr-access-logs-*/*
              - arn:aws:s3:::elastic-central-nf-access-logs-*/*
              - arn:aws:s3:::elastic-aws-emr-local-logs*/*
              - arn:aws:s3:::elastic-aws-emr-local-logs*
              - arn:aws:s3:::elastic-aws-elb-local-logs-*/*
              - arn:aws:s3:::elastic-aws-elb-local-logs-*
              - arn:aws:s3:::elastic-aws-waf-local-logs-*/*
              - arn:aws:s3:::elastic-aws-waf-local-logs-*
              - arn:aws:s3:::elastic-aws-nf-local-logs-*/*
              - arn:aws:s3:::elastic-aws-nf-local-logs-*
              - arn:aws:s3:::elastic-aws-cloudfront-local-logs-*/*
              - arn:aws:s3:::elastic-aws-cloudfront-local-logs-*
              - arn:aws:s3:::elastic-aws-cloudfront-local-logs-*/*
              - arn:aws:s3:::elastic-aws-cloudfront-local-logs-*
              - arn:aws:s3:::elastic-central-cloudfront-access-logs-*/*
              - arn:aws:s3:::elastic-central-cloudfront-access-logs-*
          - 
            Action:
              - s3:ReplicateObject
              - s3:ReplicateDelete
              - s3:ReplicateTags
              - s3:ObjectOwnerOverrideToBucketOwner
            Effect: "Allow"
            Resource:
              - arn:aws:s3:::elastic-central-elb-access-logs-*/*
              - arn:aws:s3:::elastic-central-waf-access-logs-*/*
              - arn:aws:s3:::elastic-central-emr-access-logs-*/*
              - arn:aws:s3:::elastic-central-nf-access-logs-*/*
              - arn:aws:s3:::elastic-central-cloudfront-access-logs-*/*
      ManagedPolicyName: "Elastic-AWS-S3-Replication"
      Roles: 
        - 
          Ref: "S3ReplicationRole"


  S3ElbLocalAccessLogBucket:
    Type: AWS::S3::Bucket
    DependsOn: S3LocalLoggingBucket
    DeletionPolicy: Retain
    Properties:
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: "AES256"
      BucketName: !Sub elastic-aws-elb-local-logs-${AWS::AccountId}-${AWS::Region}
      LifecycleConfiguration:
        Rules:
          - ExpirationInDays: 1
            Id: Remove replicated logs after 1 day
            NoncurrentVersionExpirationInDays: 1
            Status: Enabled
      LoggingConfiguration:
        DestinationBucketName: !Ref S3LocalLoggingBucket
        LogFilePrefix: !Sub "elastic-aws-elb-local-logs-${AWS::AccountId}-${AWS::Region}/"
      ReplicationConfiguration:
        Role: !Sub arn:aws:iam::${AWS::AccountId}:role/elastic-AWS-S3-Replication
        Rules:
          - Prefix: ""
            Status: "Enabled"
            Destination: 
              AccessControlTranslation:
                Owner: Destination
              Bucket: !Sub arn:aws:s3:::elastic-central-elb-access-logs-${LoggingAccountId}-${LoggingRegion}
              Account: !Ref LoggingAccountId      
      VersioningConfiguration:
        Status: Enabled

  S3ElbAccessLogBucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref S3ElbLocalAccessLogBucket
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Sid: AWSBucketPermissionsCheck
            Action: s3:PutObject
            Effect: Allow
            Principal:
              AWS:
                - !Sub "arn:aws:iam::${AWS::AccountId}:root"
                - "arn:aws:iam::127311923021:root"
            Resource:
              - !Sub "arn:aws:s3:::${S3ElbLocalAccessLogBucket}/*"
          - Sid: LogDelivery
            Action: s3:PutObject
            Effect: Allow
            Principal:
              Service: logdelivery.elasticloadbalancing.amazonaws.com
            Resource:
              - !Sub "arn:aws:s3:::${S3ElbLocalAccessLogBucket}/*"
            Condition:
              StringEquals:
                "s3:x-amz-acl": "bucket-owner-full-control"
          - Sid: LogDeliveryPermissionCheck
            Action: s3:GetBucketAcl
            Effect: Allow
            Principal:
              Service: delivery.logs.amazonaws.com
            Resource:
              - !Sub "arn:aws:s3:::${S3ElbLocalAccessLogBucket}"
              
  S3WafLocalAccessLogBucket:
    Type: AWS::S3::Bucket
    DependsOn: S3LocalLoggingBucket
    DeletionPolicy: Retain
    Properties:
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: "AES256"
      BucketName: !Sub elastic-aws-waf-local-logs-${AWS::AccountId}-${AWS::Region}
      LifecycleConfiguration:
        Rules:
          - ExpirationInDays: 1
            Id: Remove replicated logs after 1 day
            NoncurrentVersionExpirationInDays: 1
            Status: Enabled
      LoggingConfiguration:
        DestinationBucketName: !Ref S3LocalLoggingBucket
        LogFilePrefix: !Sub "elastic-aws-waf-local-logs-${AWS::AccountId}-${AWS::Region}/"
      ReplicationConfiguration:
        Role: !Sub arn:aws:iam::${AWS::AccountId}:role/elastic-AWS-S3-Replication
        Rules:
          - Prefix: ""
            Status: "Enabled"
            Destination:
              AccessControlTranslation:
                Owner: Destination
              Bucket: !Sub arn:aws:s3:::elastic-central-waf-access-logs-${LoggingAccountId}-${LoggingRegion}
              Account: !Ref LoggingAccountId
      VersioningConfiguration:
        Status: Enabled

  S3WafAccessLogBucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref S3WafLocalAccessLogBucket
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Sid: AWSBucketPermissionsCheck
            Action: s3:PutObject
            Effect: Allow
            Principal:
              AWS:
                - !Sub "arn:aws:iam::${AWS::AccountId}:root"
            Resource:
              - !Sub "arn:aws:s3:::${S3WafLocalAccessLogBucket}/*"
          - Sid: LogDelivery
            Action: s3:PutObject
            Effect: Allow
            Principal:
              Service: delivery.logs.amazonaws.com
            Resource:
              - !Sub "arn:aws:s3:::${S3WafLocalAccessLogBucket}/*"
            Condition:
              StringEquals:
                "s3:x-amz-acl": "bucket-owner-full-control"
          - Sid: LogDeliveryPermissionCheck
            Action: s3:GetBucketAcl
            Effect: Allow
            Principal:
              Service: delivery.logs.amazonaws.com
            Resource:
              - !Sub "arn:aws:s3:::${S3WafLocalAccessLogBucket}"

  S3EmrLocalAccessLogBucket:
    Type: AWS::S3::Bucket
    DependsOn: S3LocalLoggingBucket
    DeletionPolicy: Retain
    Properties:
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: "AES256"
      BucketName: !Sub elastic-aws-emr-local-logs-${AWS::AccountId}-${AWS::Region}
      LifecycleConfiguration:
        Rules:
          - ExpirationInDays: 1
            Id: Remove replicated logs after 1 day
            NoncurrentVersionExpirationInDays: 1
            Status: Enabled
      LoggingConfiguration:
        DestinationBucketName: !Ref S3LocalLoggingBucket
        LogFilePrefix: !Sub "elastic-aws-emr-local-logs-${AWS::AccountId}-${AWS::Region}/"
      ReplicationConfiguration:
        Role: !Sub arn:aws:iam::${AWS::AccountId}:role/elastic-AWS-S3-Replication
        Rules:
          - Prefix: ""
            Status: "Enabled"
            Destination: 
              AccessControlTranslation:
                Owner: Destination
              Bucket: !Sub arn:aws:s3:::elastic-central-emr-access-logs-${LoggingAccountId}-${LoggingRegion}
              Account: !Ref LoggingAccountId
      VersioningConfiguration:
        Status: Enabled

  S3EmrAccessLogBucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref S3EmrLocalAccessLogBucket
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Sid: AWSBucketPermissionsCheck
            Action: s3:PutObject
            Effect: Allow
            Principal:
              AWS:
                - !Sub "arn:aws:iam::${AWS::AccountId}:root"
            Resource:
              - !Sub "arn:aws:s3:::${S3EmrLocalAccessLogBucket}/*"
          - Sid: LogDelivery
            Action: s3:PutObject
            Effect: Allow
            Principal:
              Service: delivery.logs.amazonaws.com
            Resource:
              - !Sub "arn:aws:s3:::${S3EmrLocalAccessLogBucket}/*"
            Condition:
              StringEquals:
                "s3:x-amz-acl": "bucket-owner-full-control"
          - Sid: LogDeliveryPermissionCheck
            Action: s3:GetBucketAcl
            Effect: Allow
            Principal:
              Service: delivery.logs.amazonaws.com
            Resource:
              - !Sub "arn:aws:s3:::${S3EmrLocalAccessLogBucket}"

  S3NfLocalAccessLogBucket:
    Type: AWS::S3::Bucket
    DependsOn: S3LocalLoggingBucket
    DeletionPolicy: Retain
    Properties:
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: "AES256"
      BucketName: !Sub elastic-aws-nf-local-logs-${AWS::AccountId}-${AWS::Region}
      LifecycleConfiguration:
        Rules:
          - ExpirationInDays: 1
            Id: Remove replicated logs after 1 day
            NoncurrentVersionExpirationInDays: 1
            Status: Enabled
      LoggingConfiguration:
        DestinationBucketName: !Ref S3LocalLoggingBucket
        LogFilePrefix: !Sub "elastic-aws-nf-local-logs-${AWS::AccountId}-${AWS::Region}/"
      ReplicationConfiguration:
        Role: !Sub arn:aws:iam::${AWS::AccountId}:role/elastic-AWS-S3-Replication
        Rules:
          - Prefix: ""
            Status: "Enabled"
            Destination: 
              AccessControlTranslation:
                Owner: Destination
              Bucket: !Sub arn:aws:s3:::elastic-central-nf-access-logs-${LoggingAccountId}-${LoggingRegion}
              Account: !Ref LoggingAccountId
      VersioningConfiguration:
        Status: Enabled

  S3NfAccessLogBucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref S3NfLocalAccessLogBucket
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Sid: AWSBucketPermissionsCheck
            Action: s3:PutObject
            Effect: Allow
            Principal:
              AWS:
                - !Sub "arn:aws:iam::${AWS::AccountId}:root"
            Resource:
              - !Sub "arn:aws:s3:::${S3NfLocalAccessLogBucket}/*"
          - Sid: LogDelivery
            Action: s3:PutObject
            Effect: Allow
            Principal:
              Service: delivery.logs.amazonaws.com
            Resource:
              - !Sub "arn:aws:s3:::${S3NfLocalAccessLogBucket}/*"
            Condition:
              StringEquals:
                "s3:x-amz-acl": "bucket-owner-full-control"
          - Sid: LogDeliveryPermissionCheck
            Action: s3:GetBucketAcl
            Effect: Allow
            Principal:
              Service: delivery.logs.amazonaws.com
            Resource:
              - !Sub "arn:aws:s3:::${S3NfLocalAccessLogBucket}"

  S3CloudfrontLocalAccessLogBucket:
    Type: AWS::S3::Bucket
    DependsOn: S3LocalLoggingBucket
    DeletionPolicy: Retain
    Properties:
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: "AES256"
      BucketName: !Sub elastic-aws-cloudfront-local-logs-${AWS::AccountId}-${AWS::Region}
      LifecycleConfiguration:
        Rules:
          - ExpirationInDays: 1
            Id: Remove replicated logs after 1 day
            NoncurrentVersionExpirationInDays: 1
            Status: Enabled
      LoggingConfiguration:
        DestinationBucketName: !Ref S3LocalLoggingBucket
        LogFilePrefix: !Sub "elastic-aws-cloudfront-local-logs-${AWS::AccountId}-${AWS::Region}/"
      ReplicationConfiguration:
        Role: !Sub arn:aws:iam::${AWS::AccountId}:role/elastic-AWS-S3-Replication
        Rules:
          - Prefix: ""
            Status: "Enabled"
            Destination: 
              AccessControlTranslation:
                Owner: Destination
              Bucket: !Sub arn:aws:s3:::elastic-central-cloudfront-access-logs-${LoggingAccountId}-${LoggingRegion}
              Account: !Ref LoggingAccountId
      VersioningConfiguration:
        Status: Enabled

  S3CloudfrontAccessLogBucketPolicy:
    Type: AWS::S3::BucketPolicy
    Properties:
      Bucket: !Ref S3CloudfrontLocalAccessLogBucket
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Sid: AWSBucketPermissionsCheck
            Action: s3:PutObject
            Effect: Allow
            Principal:
              AWS:
                - !Sub "arn:aws:iam::${AWS::AccountId}:root"
            Resource:
              - !Sub "arn:aws:s3:::${S3CloudfrontLocalAccessLogBucket}/*"
          - Sid: LogDelivery
            Action: s3:PutObject
            Effect: Allow
            Principal:
              Service: delivery.logs.amazonaws.com
            Resource:
              - !Sub "arn:aws:s3:::${S3CloudfrontLocalAccessLogBucket}/*"
            Condition:
              StringEquals:
                "s3:x-amz-acl": "bucket-owner-full-control"
          - Sid: LogDeliveryPermissionCheck
            Action: s3:GetBucketAcl
            Effect: Allow
            Principal:
              Service: delivery.logs.amazonaws.com
            Resource:
              - !Sub "arn:aws:s3:::${S3CloudfrontLocalAccessLogBucket}"
              
  S3LocalLoggingBucket:
    Type: AWS::S3::Bucket
    DeletionPolicy: Retain
    Properties:
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: "AES256"
      BucketName: !Sub elastic-aws-local-s3-access-logs-${AWS::AccountId}-${AWS::Region}
      LifecycleConfiguration:
        Rules:
          - ExpirationInDays: 1
            Id: Remove replicated logs after 1 day
            NoncurrentVersionExpirationInDays: 1
            Status: Enabled
      ReplicationConfiguration:
        Role: !Sub arn:aws:iam::${AWS::AccountId}:role/elastic-AWS-S3-Replication
        Rules:
          - Prefix: ""
            Status: "Enabled"
            Destination: 
              AccessControlTranslation:
                Owner: Destination
              Bucket: !Sub arn:aws:s3:::elastic-central-s3-access-logs-${LoggingAccountId}-${LoggingRegion}
              Account: !Ref LoggingAccountId
      VersioningConfiguration:
        Status: Enabled
        
  ElasticServerlessForwarderEventMacro:
    Type: AWS::Serverless::Application
    Condition: ShouldDeployElasticServerlessForwarder
    Properties:
      Location:
        ApplicationId: arn:aws:serverlessrepo:eu-central-1:267093732750:applications/helper-macro-elastic-serverless-forwarder
        SemanticVersion: 1.9.0
    DependsOn:
    - TriggersBootstrapLambda
    Metadata:
      SamResourceId: ElasticServerlessForwarderEventMacro

  ElasticServerlessForwarderApplication:
    Type: AWS::Serverless::Application
    Condition: ShouldDeployElasticServerlessForwarder
    Properties:
      Location:
        ApplicationId: arn:aws:serverlessrepo:eu-central-1:267093732750:applications/helper-application-elastic-serverless-forwarder
        SemanticVersion: 1.9.0
      Parameters:
        ElasticServerlessForwarderS3ConfigFile: !Sub s3://${S3ConfigFileBucket}/config.yml
        ElasticServerlessForwarderSSMSecrets: !Ref ElasticSecret
        ElasticServerlessForwarderKMSKeys: !GetAtt ElasticSSMSecretEncryptionKey.Arn
        ElasticServerlessForwarderSQSEvents: ""
        ElasticServerlessForwarderS3SQSEvents: ""
        ElasticServerlessForwarderKinesisEvents:
          Fn::Join:
          - ','
          - Ref: KinesisDataStreamArn
        ElasticServerlessForwarderCloudWatchLogsEvents:
          Fn::Join:
          - ','
          - Ref: CloudWatchLogGroupArns
        ElasticServerlessForwarderS3Buckets: ""
        ElasticServerlessForwarderSecurityGroups: !If
          - ShouldDeployElasticForwarderInVPC
          - !GetAtt ElasticForwarderSecurityGroup.GroupId
          - ""
        ElasticServerlessForwarderSubnets: !If
          - ShouldDeployElasticForwarderInVPC
          - Fn::Join: [',', !Ref SubnetIds]
          - ""
    DependsOn: 
    - ElasticServerlessForwarderEventMacro
    Metadata:
      SamResourceId: ElasticServerlessForwarderApplication
      
  S3ConfigFileBucket:       #Bucket to store the config.yaml file
    Type: AWS::S3::Bucket
    Condition: ShouldDeployElasticServerlessForwarder
    DeletionPolicy: Retain
    Properties:
      BucketName: !Sub aws-helper-config-bucket-${AWS::AccountId}-${AWS::Region}      
      VersioningConfiguration:
        Status: Enabled

  S3ConfigFileBucketPolicy:
    Type: AWS::S3::BucketPolicy
    Condition: ShouldDeployElasticServerlessForwarder
    DependsOn: S3ConfigFileBucket
    Properties:
      Bucket: !Ref S3ConfigFileBucket
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Sid: AWSBucketPermissions
            Action:
              - s3:PutObject
              - s3:GetObject
              - s3:PutObject
              - s3:DeleteObject
              - s3:GetBucketAcl
              - s3:ListBucket
            Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com 
            Resource:
              - Fn::Join:
                  - ''
                  - - 'arn:aws:s3:::'
                    - Ref: 'S3ConfigFileBucket'
                    - '/*'
              - Fn::Join:
                  - ''
                  - - 'arn:aws:s3:::'
                    - Ref: 'S3ConfigFileBucket'

  ElasticBootstrapLambdaForConfigFile:
    Type: 'AWS::Serverless::Function'
    Condition: ShouldDeployElasticServerlessForwarder
    DependsOn:
    - S3ConfigFileBucketPolicy
    - ElasticSecret
    Properties:
      Handler: lambda_function.lambda_handler
      Role: !GetAtt ElasticBootstrapLambdaExecutionRole.Arn
      Runtime: python3.11
      Timeout: 300
      MemorySize: 128
      CodeUri:
        Bucket: bootstrap-lambda-code
        Key: MemberAccount-code/ElasticBootstrapLambdaMemberAccount.zip
      Environment:
        Variables:
          ELASTIC_SECRET_ARN: !Ref ElasticSecret
          S3_BUCKET_NAME: !Ref S3ConfigFileBucket
          INGEST_CLOUDWATCH_LOGS: !Ref IngestCloudWatchLogs
          CLOUDWATCH_LOG_GROUP_ARNS: !If
            - ShouldIngestCloudWatchLogs
            - Fn::Join: [',', !Ref CloudWatchLogGroupArns]
            - ""  # Set to an empty string if ShouldIngestCloudWatchLogs is false  
          INGEST_KINESIS_LOGS: !Ref IngestKinesisLogs
          KINESIS_DATA_STREAM_ARNS: !If
            - ShouldIngestKinesisDataStream
            - Fn::Join: [',', !Ref KinesisDataStreamArn]
            - ""  # Set to an empty string if ShouldIngestKinesisDataStream is false

  ElasticBootstrapLambdaExecutionRole:
    Type: 'AWS::IAM::Role'
    Condition: ShouldDeployElasticServerlessForwarder
    Properties:
      AssumeRolePolicyDocument: 
        Version: "2012-10-17"
        Statement: 
          - Effect: "Allow"
            Principal: 
              Service: 
              - "lambda.amazonaws.com"
            Action: 
              - "sts:AssumeRole"
      Path: "/"
      ManagedPolicyArns:
        - 'arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'

  RolePolicies: 
    Type: 'AWS::IAM::Policy'
    Condition: ShouldDeployElasticServerlessForwarder
    Properties: 
      PolicyName: "ElasticBootstrapLambdaPolicy"
      PolicyDocument: 
        Version: "2012-10-17"
        Statement: 
          - Effect: "Allow"
            Action:
            - "s3:PutObject"
            Resource: "*" 
      Roles: 
        - Ref: "ElasticBootstrapLambdaExecutionRole"

  TriggersBootstrapLambda:
    Type: 'Custom::RunCode'
    Condition: ShouldDeployElasticServerlessForwarder
    DependsOn: ElasticBootstrapLambdaForConfigFile
    DeletionPolicy: Retain 
    Properties:
      ServiceToken: !GetAtt ElasticBootstrapLambdaForConfigFile.Arn
      
  ElasticForwarderSecurityGroup:
    Type: AWS::EC2::SecurityGroup
    Condition: ShouldDeployVPCResource
    Properties:
      GroupDescription: Elastic SecurityGroup 
      VpcId: !Ref VPCId
      SecurityGroupIngress:
        - IpProtocol: tcp
          FromPort: 0
          ToPort: 65535
          CidrIp: 0.0.0.0/0
      SecurityGroupEgress:
        - IpProtocol: tcp
          FromPort: 443
          ToPort: 443
          CidrIp: 0.0.0.0/0
        - IpProtocol: tcp
          FromPort: 9243
          ToPort: 9243
          CidrIp: 0.0.0.0/0
      
  ServerlessLambdaRolePolicies: 
    Type: 'AWS::IAM::Policy'
    Condition: ShouldDeployVPCResource
    Properties: 
      PolicyName: "ElasticServerlessLambdaPolicy"
      PolicyDocument: 
        Version: "2012-10-17"
        Statement: 
          - Effect: "Allow"
            Action:
            - "ec2:CreateSecurityGroup"
            - "ec2:AuthorizeSecurityGroupIngress"
            - "ec2:CreateVpcEndpoint"
            - "ec2:DescribeVpcEndpoints"
            - "route53:CreateHostedZone"
            - "route53:ChangeResourceRecordSets"
            - "route53:GetChange"
            - "ec2:DescribeVpcs"
            - "s3:PutObject"
            - "route53:ListHostedZonesByName"
            - "route53:ListHostedZonesByVPC"
            Resource: "*" 
      Roles: 
        - Ref: "ServerlessLambdaExecutionRole"
              
  ServerlessLambdaExecutionRole:
    Type: 'AWS::IAM::Role'
    Condition: ShouldDeployVPCResource
    Properties:
      AssumeRolePolicyDocument: 
        Version: "2012-10-17"
        Statement: 
          - Effect: "Allow"
            Principal: 
              Service: 
              - "lambda.amazonaws.com"
            Action: 
              - "sts:AssumeRole"
      Path: "/"
      ManagedPolicyArns:
        - 'arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'
        
  ElasticServerlessBootstrapFunction:
    Type: AWS::Serverless::Function
    Condition: ShouldDeployVPCResource
    Properties:
      Handler: index.lambda_handler
      Role: !GetAtt ServerlessLambdaExecutionRole.Arn
      Runtime: python3.8
      InlineCode: |
            import boto3
            import boto3
            import boto3
            import os
            import uuid
            import random
            import string
            import cfnresponse

            def create_security_group(vpc_id, group_description):
                # Generate a random suffix for the group name
                random_suffix = ''.join(random.choices(string.ascii_lowercase + string.digits, k=6))
                group_name = f'ElasticProxySecurityGroup_{random_suffix}'
                            
                ec2 = boto3.resource('ec2')
                security_group = ec2.create_security_group(
                    VpcId=vpc_id,
                    GroupName=group_name,
                    Description=group_description
                )
                security_group.authorize_ingress(
                    IpProtocol='tcp',
                    FromPort=443,
                    ToPort=443,
                    CidrIp='0.0.0.0/0'
                )
                security_group.authorize_ingress(
                    IpProtocol='tcp',
                    FromPort=9243,
                    ToPort=9243,
                    CidrIp='0.0.0.0/0'
                )
                return security_group.id

            def extract_dns_entries(response):
                # Check if 'VpcEndpoint' key is present in the response
                vpc_endpoint_info = response.get('VpcEndpoint', {})

                # Extract DNS entries from 'DnsEntries' in 'VpcEndpoint' info
                dns_entries = vpc_endpoint_info.get('DnsEntries', [])

                if not dns_entries:
                    raise ValueError("VpcEndpoint DNS entries not found in the response.")

                # Use the first DNS entry for creating the CNAME record
                dns_name = dns_entries[0].get('DnsName')

                if dns_name is not None:
                    print("VPC Endpoint DNS Entry:", dns_name)
                else:
                    raise ValueError("VpcEndpoint DNS entry is None.")

                return dns_name
                            
            def check_vpc_endpoint_exists(vpc_id, service_name):
                ec2 = boto3.client('ec2')
                response = ec2.describe_vpc_endpoints(
                    Filters=[
                        {'Name': 'vpc-id', 'Values': [vpc_id]},
                        {'Name': 'service-name', 'Values': [service_name]}
                    ]
                )
                endpoints = response.get('VpcEndpoints', [])
                return bool(endpoints)

            def create_vpc_endpoint(vpc_id, subnet_ids, security_group_id, region, service_name):    
                ec2 = boto3.client('ec2', region_name=region)
                response = ec2.create_vpc_endpoint(
                    VpcId=vpc_id,
                    ServiceName=service_name,
                    SubnetIds=subnet_ids,
                    VpcEndpointType='Interface',
                    SecurityGroupIds=[security_group_id]
                )
                            
                # Ensure 'VpcEndpointId' is present in the response
                vpc_endpoint_id = response.get('VpcEndpoint', {}).get('VpcEndpointId')
                if not vpc_endpoint_id:
                    raise ValueError("VpcEndpointId not found in the response.")

                # Extract DNS entries from the response
                dns_name = extract_dns_entries(response)

                print("Create VPC Endpoint Response:", response)
                return vpc_endpoint_id, dns_name
                        
            def check_hosted_zone_exists(vpc_id, private_hosted_zone, region):
                route53 = boto3.client('route53')
                response = route53.list_hosted_zones_by_vpc(VPCId=vpc_id, VPCRegion=region)
                
                hosted_zones = response.get('HostedZoneSummaries', [])
                print(hosted_zones)
                
                # Add a dot at the end of the private_hosted_zone name
                hosted_zone_name = private_hosted_zone + '.' if not private_hosted_zone.endswith('.') else private_hosted_zone
                
                # Check if the hosted zone exists with the specified name
                hosted_zone_present = any(zone['Name'] == hosted_zone_name for zone in hosted_zones)
                print(hosted_zone_present)
                
                return hosted_zone_present

            def create_hosted_zone(vpc_id, region, private_hosted_zone):
                route53 = boto3.client('route53')
                caller_reference = str(uuid.uuid4())
                response = route53.create_hosted_zone(
                    Name=private_hosted_zone,
                    VPC={
                        'VPCId': vpc_id,
                        'VPCRegion': region
                    },
                    CallerReference=caller_reference
                )
                # Extract Hosted Zone Id
                hosted_zone_id = response['HostedZone']['Id']
                return hosted_zone_id

            def create_cname_record(hosted_zone_id, region, dns_name):
                try:
                    print("Debug - VPC Endpoint DNS Entry:", dns_name)

                    if dns_name is not None and isinstance(dns_name, str):
                        route53 = boto3.client('route53')
                        response = route53.change_resource_record_sets(
                            HostedZoneId=hosted_zone_id,
                            ChangeBatch={
                                'Changes': [
                                    {
                                        'Action': 'CREATE',
                                        'ResourceRecordSet': {
                                            'Name': f'*.{region}.aws.found.io',
                                            'Type': 'CNAME',
                                            'TTL': 60,
                                            'ResourceRecords': [
                                                {
                                                    'Value': dns_name
                                                }
                                            ]
                                        }
                                    }
                                ]
                            }
                        )
                        # Print the response for debugging purposes
                        print(response)
                        print("Debug - CNAME Record created successfully.")
                    else:
                        print("Warning: VpcEndpoint DNS entry is None or not in the expected format.")
                except Exception as e:
                    print(f"Error creating CNAME record: {e}")
                    raise
                                
            def check_s3_gateway_endpoint_exists(vpc_id, region):
                ec2 = boto3.client('ec2', region_name=region)
                response = ec2.describe_vpc_endpoints(
                    Filters=[
                        {'Name': 'vpc-id', 'Values': [vpc_id]},
                        {'Name': 'service-name', 'Values': ['com.amazonaws.' + region + '.s3']}
                    ]
                )
                endpoints = response.get('VpcEndpoints', [])
                return bool(endpoints)
                        
            def create_s3_gateway_endpoint(vpc_id, route_table_id, region):
                ec2_client = boto3.client('ec2', region_name=region)

                response = ec2_client.create_vpc_endpoint(
                    VpcId=vpc_id,
                    ServiceName=f'com.amazonaws.{region}.s3',
                    VpcEndpointType='Gateway',
                    RouteTableIds=route_table_id
                )

                return response
                
            def check_kinesis_interface_endpoint_exists(vpc_id, region):
                ec2 = boto3.client('ec2', region_name=region)
                response = ec2.describe_vpc_endpoints(
                    Filters=[
                        {'Name': 'vpc-id', 'Values': [vpc_id]},
                        {'Name': 'service-name', 'Values': ['com.amazonaws.' + region + '.kinesis-streams']}
                    ]
                )
                endpoints = response.get('VpcEndpoints', [])
                return bool(endpoints)

            def create_kinesis_data_stream_interface_endpoint(vpc_id, subnet_ids, security_group_id, region):
                client = boto3.client('ec2', region_name=region)

                response = client.create_vpc_endpoint(
                    VpcId=vpc_id,
                    ServiceName=f'com.amazonaws.{region}.kinesis-streams',
                    VpcEndpointType='Interface',
                    SubnetIds=subnet_ids,
                    SecurityGroupIds=[security_group_id]
                )

                return response
                
            def check_secretmanager_interface_endpoint_exists(vpc_id, region):
                ec2 = boto3.client('ec2', region_name=region)
                response = ec2.describe_vpc_endpoints(
                    Filters=[
                        {'Name': 'vpc-id', 'Values': [vpc_id]},
                        {'Name': 'service-name', 'Values': ['com.amazonaws.' + region + '.secretsmanager']}
                    ]
                )
                endpoints = response.get('VpcEndpoints', [])
                return bool(endpoints)

            def create_secretmanager_interface_endpoint(vpc_id, subnet_ids, security_group_id, region):
                client = boto3.client('ec2', region_name=region)

                response = client.create_vpc_endpoint(
                    VpcId=vpc_id,
                    ServiceName=f'com.amazonaws.{region}.secretsmanager',
                    VpcEndpointType='Interface',
                    SubnetIds=subnet_ids,
                    SecurityGroupIds=[security_group_id]
                )

                return response
                            
            def check_kms_interface_endpoint_exists(vpc_id, region):
                ec2 = boto3.client('ec2', region_name=region)
                response = ec2.describe_vpc_endpoints(
                    Filters=[
                        {'Name': 'vpc-id', 'Values': [vpc_id]},
                        {'Name': 'service-name', 'Values': ['com.amazonaws.' + region + '.kms']}
                    ]
                )
                endpoints = response.get('VpcEndpoints', [])
                return bool(endpoints)

            def create_kms_interface_endpoint(vpc_id, subnet_ids, security_group_id, region):
                client = boto3.client('ec2', region_name=region)

                response = client.create_vpc_endpoint(
                    VpcId=vpc_id,
                    ServiceName=f'com.amazonaws.{region}.kms',
                    VpcEndpointType='Interface',
                    SubnetIds=subnet_ids,
                    SecurityGroupIds=[security_group_id]
                )

                return response

            def check_cw_logs_interface_endpoint_exists(vpc_id, region):
                ec2 = boto3.client('ec2', region_name=region)
                response = ec2.describe_vpc_endpoints(
                    Filters=[
                        {'Name': 'vpc-id', 'Values': [vpc_id]},
                        {'Name': 'service-name', 'Values': ['com.amazonaws.' + region + '.logs']}
                    ]
                )
                endpoints = response.get('VpcEndpoints', [])
                return bool(endpoints)

            def create_cw_logs_interface_endpoint(vpc_id, subnet_ids, security_group_id, region):
                client = boto3.client('ec2', region_name=region)

                response = client.create_vpc_endpoint(
                    VpcId=vpc_id,
                    ServiceName=f'com.amazonaws.{region}.logs',
                    VpcEndpointType='Interface',
                    SubnetIds=subnet_ids,
                    SecurityGroupIds=[security_group_id]
                )

                return response
                
            def check_sqs_interface_endpoint_exists(vpc_id, region):
                ec2 = boto3.client('ec2', region_name=region)
                response = ec2.describe_vpc_endpoints(
                    Filters=[
                        {'Name': 'vpc-id', 'Values': [vpc_id]},
                        {'Name': 'service-name', 'Values': ['com.amazonaws.' + region + '.sqs']}
                    ]
                )
                endpoints = response.get('VpcEndpoints', [])
                return bool(endpoints)
                    
            def create_sqs_interface_endpoint(vpc_id, subnet_ids, security_group_id, region):
                client = boto3.client('ec2', region_name=region)

                response = client.create_vpc_endpoint(
                    VpcId=vpc_id,
                    ServiceName=f'com.amazonaws.{region}.sqs',
                    VpcEndpointType='Interface',
                    SubnetIds=subnet_ids,
                    SecurityGroupIds=[security_group_id]
                )

                return response

            def lambda_handler(event, context):
                vpc_id = os.getenv('VPC_ID')
                subnet_ids = os.getenv('SUBNET_IDS').split(',')
                route_table_id = os.getenv('ROUTE_TABLE_ID').split(',')
                region = os.getenv('REGION')
                service_name = os.getenv('ServiceName')
                private_hosted_zone = os.getenv('Private_Hosted_Zone')
                responseData = {}
                
                try:
                    security_group_id = create_security_group(vpc_id, 'Elastic Proxy SecurityGroup')
                    # Check if VPC endpoint already exists
                    if not check_vpc_endpoint_exists(vpc_id, service_name):
                        # VPC endpoint doesn't exist, create it
                        vpc_endpoint_id, dns_name = create_vpc_endpoint(vpc_id, subnet_ids, security_group_id, region, service_name)
                    else:
                        print(f"VPC endpoint for service {service_name} already exists in VPC {vpc_id}. Skipping creation.")
                        dns_name = None
                        
                    # Check if hosted zone already exists
                    if not check_hosted_zone_exists(vpc_id, private_hosted_zone, region):
                        # Hosted zone doesn't exist, create it
                        hosted_zone_id = create_hosted_zone(vpc_id, region, private_hosted_zone)
                        # Use the DNS name obtained from create_vpc_endpoint function
                        if dns_name is not None:
                            create_cname_record(hosted_zone_id, region, dns_name)
                        else:
                            print("VpcEndpoint DNS entry is None.")
                    else:
                        print("Hosted zone already exists. Skipping creation.")
                    
                    # Check if S3 Gateway endpoint already exists
                    if not check_s3_gateway_endpoint_exists(vpc_id, region):
                        # S3 Gateway endpoint doesn't exist, create it
                        s3_response = create_s3_gateway_endpoint(vpc_id, route_table_id, region)
                        print("S3 Gateway VPC Endpoint created successfully:")
                        print(s3_response)
                    else:
                        print("S3 Gateway endpoint already exists. Skipping creation.")
                    
                    # Check if SQS Interface endpoint already exists
                    if not check_sqs_interface_endpoint_exists(vpc_id, region):
                        # SQS Interface endpoint doesn't exist, create it
                        sqs_response = create_sqs_interface_endpoint(vpc_id, subnet_ids, security_group_id, region)
                        print("SQS Interface VPC Endpoint created successfully:")
                        print(sqs_response)
                    else:
                        print("SQS Interface endpoint already exists. Skipping creation.")
                    
                    # Check if user wants to ingest Kinesis logs based on a parameter
                    ingest_kinesis_logs = os.getenv('INGEST_KINESIS_LOGS', 'No').strip().lower()

                    if ingest_kinesis_logs == 'yes':
                        # Create Kinesis datastream Interface VPC endpoint
                        if not check_kinesis_interface_endpoint_exists(vpc_id, region):
                            kinesis_response = create_kinesis_data_stream_interface_endpoint(vpc_id, subnet_ids, security_group_id, region)
                            print("Kinesis Data Stream VPC Endpoint created successfully:")
                            print(kinesis_response)
                        else:
                            print("Kinesis Data Stream Interface endpoint already exists. Skipping creation.")
                    else:
                        print("Not creating Kinesis Data Stream endpoint.")

                    # Check if Secret Manager Interface endpoint already exists
                    if not check_secretmanager_interface_endpoint_exists(vpc_id, region):
                        # Secret Manager Interface endpoint doesn't exist, create it
                        ssm_response = create_secretmanager_interface_endpoint(vpc_id, subnet_ids, security_group_id, region)
                        print("Secret Manager Interface VPC Endpoint created successfully:")
                        print(ssm_response)
                    else:
                        print("Secret Manager Interface endpoint already exists. Skipping creation.")

                    # Check if KMS Interface endpoint already exists
                    if not check_kms_interface_endpoint_exists(vpc_id, region):
                        # KMS Interface endpoint doesn't exist, create it
                        kms_response = create_kms_interface_endpoint(vpc_id, subnet_ids, security_group_id, region)
                        print("Key Management Service Interface VPC Endpoint created successfully:")
                        print(kms_response)
                    else:
                        print("KMS Interface endpoint already exists. Skipping creation.")

                    # Check if user wants to ingest Cloudwatch logs based on a parameter
                    ingest_cloudwatch_logs = os.getenv('INGEST_CLOUDWATCH_LOGS', 'No').strip().lower()

                    if ingest_cloudwatch_logs == 'yes':
                        # Create Cloudwatch Log Interface VPC endpoint
                        if not check_cw_logs_interface_endpoint_exists(vpc_id, region):
                            logs_response = create_cw_logs_interface_endpoint(vpc_id, subnet_ids, security_group_id, region)
                            print("CloudWatch Logs Interface VPC Endpoint created successfully:")
                            print(logs_response)
                        else:
                            print("CloudWatch Logs Interface endpoint already exists. Skipping creation.")
                    else:
                        print("Not creating Kinesis Data Stream endpoint.")
                    
                    cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData)

                except Exception as e:
                    # Send a failure response with the error reason
                    cfnresponse.send(event, context, cfnresponse.FAILED, responseData, reason=str(e))
      Timeout: 900
      Environment:
        Variables:
          VPC_ID: !Ref VPCId
          SUBNET_IDS: !Join [',', !Ref SubnetIds]
          ServiceName: 
            !FindInMap 
              - VPCServiceName
              - !Ref 'AWS::Region'
              - service
          Private_Hosted_Zone:
            !FindInMap 
              - PrivateHostedZoneDNSName
              - !Ref 'AWS::Region'
              - HostedZone
          REGION: !Sub ${AWS::Region}
          ROUTE_TABLE_ID: !Join [',', !Ref RouteTableIds]
          INGEST_KINESIS_LOGS: !Ref IngestKinesisLogs
          INGEST_CLOUDWATCH_LOGS: !Ref IngestCloudWatchLogs
    
  TriggersServerlessBootstrapLambdaFunction:
    Type: 'Custom::RunCode'
    Condition: ShouldDeployVPCResource
    DeletionPolicy: Retain
    DependsOn: ElasticServerlessBootstrapFunction
    Properties:
      ServiceToken: !GetAtt ElasticServerlessBootstrapFunction.Arn
      
  KinesisFireHose:
    Type: AWS::KinesisFirehose::DeliveryStream
    Condition: ShouldIngestLogsViaKinesisFireHose
    DependsOn: KinesisFireHoseBackupBucket
    Properties:
      DeliveryStreamType: DirectPut   
      HttpEndpointDestinationConfiguration:
        EndpointConfiguration:
          AccessKey: !Ref ElasticAPIKey
          Name: "Elastic"
          Url: !Ref ElasticEndpointURL
        RequestConfiguration:
          ContentEncoding: GZIP
        BufferingHints:
          IntervalInSeconds: 60
          SizeInMBs: 1
        RoleARN: !GetAtt KinesisFireHoseRole.Arn
        RetryOptions:
          DurationInSeconds: 300
        CloudWatchLoggingOptions:
            Enabled: true
            LogGroupName: !Ref FireHoseLogGroup
            LogStreamName: !Ref DestinationErrorLogStream
        S3BackupMode: FailedDataOnly
        S3Configuration:
          BucketARN: !Sub "arn:aws:s3:::${KinesisFireHoseBackupBucket}"
          CompressionFormat: UNCOMPRESSED
          RoleARN: !GetAtt KinesisFireHoseRole.Arn
          
  KinesisFireHoseRole:
    Type: 'AWS::IAM::Role'
    Condition: ShouldIngestLogsViaKinesisFireHose
    Properties:
      AssumeRolePolicyDocument: 
        Version: "2012-10-17"
        Statement: 
          - Effect: "Allow"
            Principal: 
              Service: 
              - "firehose.amazonaws.com"
            Action: 
              - "sts:AssumeRole"
      Path: "/"

  KinesisFireHoseRolePolicies: 
    Type: 'AWS::IAM::Policy'
    Condition: ShouldIngestLogsViaKinesisFireHose
    Properties:
      PolicyName: KinesisFireHoseAccessS3
      PolicyDocument: 
        Version: "2012-10-17"
        Statement: 
          - Effect: "Allow"
            Action:
            - "s3:AbortMultipartUpload"
            - "s3:GetBucketLocation"
            - "s3:GetObject"
            - "s3:ListBucket"
            - "s3:ListBucketMultipartUploads"
            - "s3:PutObject"
            Resource:
            - !Sub "arn:aws:s3:::${KinesisFireHoseBackupBucket}/*"
            - !Sub "arn:aws:s3:::${KinesisFireHoseBackupBucket}"
      Roles: 
        - Ref: "KinesisFireHoseRole"
        
  FireHoseLogGroup:
    Type: "AWS::Logs::LogGroup"
    Condition: ShouldIngestLogsViaKinesisFireHose
    Properties:
      RetentionInDays: 1

  DestinationErrorLogStream:
    Type: "AWS::Logs::LogStream"
    Condition: ShouldIngestLogsViaKinesisFireHose
    Properties:
      LogGroupName: !Ref FireHoseLogGroup
      LogStreamName: "DestinationDelivery"
      
  KinesisFireHoseBackupBucket:       #Bucket to store the failed data from Kinesis Firehose
    Type: AWS::S3::Bucket
    Condition: ShouldIngestLogsViaKinesisFireHose
    DeletionPolicy: Retain
    Properties:
      BucketName: !Sub elastic-kinesisfirehose-backup-${AWS::AccountId}-${AWS::Region}     
      VersioningConfiguration:
        Status: Enabled

  KinesisFireHoseBackupBucketPolicy:
    Type: AWS::S3::BucketPolicy
    DependsOn: KinesisFireHoseBackupBucket
    Condition: ShouldIngestLogsViaKinesisFireHose
    Properties:
      Bucket: !Ref KinesisFireHoseBackupBucket
      PolicyDocument:
        Version: 2012-10-17
        Statement:
          - Sid: KinesisFireHoseBackupBucketPermissions
            Action:
              - s3:PutObject
              - s3:GetBucketAcl
              - s3:ListBucket
            Effect: Allow
            Principal:
              Service:
                - firehose.amazonaws.com 
            Resource:
              - Fn::Join:
                  - ''
                  - - 'arn:aws:s3:::'
                    - Ref: 'KinesisFireHoseBackupBucket'
                    - '/*'
              - Fn::Join:
                  - ''
                  - - 'arn:aws:s3:::'
                    - Ref: 'KinesisFireHoseBackupBucket'
                    
  ElasticAgentLambdaRolePolicy: 
    Type: 'AWS::IAM::Policy'
    Condition: ShouldIngestEC2InstanceLogs
    Properties: 
      PolicyName: "ElasticAgentLambdaRolePolicy"
      PolicyDocument: 
        Version: "2012-10-17"
        Statement: 
          - Effect: "Allow"
            Action:
            - "cloudformation:CreateStack"
            - "ec2:*"
            - "ssm:PutParameter"
            - "s3:GetObject"
            - "s3:PutObject"
            Resource: "*" 
      Roles: 
        - Ref: "ElasticAgentLambdaExecutionRole"
              
  ElasticAgentLambdaExecutionRole:
    Type: 'AWS::IAM::Role'
    Condition: ShouldIngestEC2InstanceLogs
    Properties:
      AssumeRolePolicyDocument: 
        Version: "2012-10-17"
        Statement: 
          - Effect: "Allow"
            Principal: 
              Service: 
              - "lambda.amazonaws.com"
            Action: 
              - "sts:AssumeRole"
      Path: "/"
      ManagedPolicyArns:
        - 'arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'
        
  ElasticAgentLambdaFunction:
    Type: AWS::Serverless::Function
    Condition: ShouldIngestEC2InstanceLogs
    Properties:
      Handler: index.lambda_handler
      Role: !GetAtt ElasticAgentLambdaExecutionRole.Arn
      Runtime: python3.9
      InlineCode: |
            import boto3
            import os
            import botocore
            import json
            import uuid
            import random
            import string
            import cfnresponse

            def lambda_handler(event, context):
                
                responseData = {}                
                # Generate a random suffix adhering to the CloudFormation stack name pattern
                random_suffix = ''.join(random.choices(string.ascii_letters + string.digits, k=6))

                # Combine the suffix with a prefix adhering to the pattern (e.g., "Elastic-Agent-")
                stack_name = 'Elastic-Agent-' + random_suffix
                
                # Replace these values with your own
                s3_bucket = 'elastic-proxy'
                path = 'elastic-ec2-log-ingestion.json'
                stack_name = stack_name

                # Extract parameters from the Lambda input
                kibana_url = os.getenv('KibanaURL')
                elasticsearch_username = os.getenv('ELASTICSEARCHUSERNAME')
                elasticsearch_password = os.getenv('ELASTICSEARCHPASSWORD')
                elasticsearch_deploymentid = os.getenv('ElasticSearchDeploymentID')
                elasticsearch_deploymentversion = os.getenv('DeploymentVersion')
                region = os.getenv('REGION')
                ami_id = os.getenv('AMIID')

                # Set up Boto3 clients
                s3_client = boto3.client('s3', region_name=region)
                cloudformation_client = boto3.client('cloudformation', region_name=region)
                
                # Fetch the CloudFormation Template from S3
                try:
                    response = s3_client.get_object(Bucket=s3_bucket, Key=path)
                    template_body = response['Body'].read().decode('utf-8')
                except botocore.exceptions.ClientError as e:
                    print(f"Error fetching template from S3: {e}")
                    return {
                        'statusCode': 500,
                        'body': json.dumps('Error fetching template from S3')
                    }
                
                # Deploy the CloudFormation Template
                try:
                    response = cloudformation_client.create_stack(
                        StackName=stack_name,
                        TemplateBody=template_body,
                        Parameters=[
                            {'ParameterKey': 'KibanaURL', 'ParameterValue': kibana_url},
                            {'ParameterKey': 'AMIID', 'ParameterValue': ami_id},
                            {'ParameterKey': 'ELASTICSEARCHUSERNAME', 'ParameterValue': elasticsearch_username},
                            {'ParameterKey': 'ELASTICSEARCHPASSWORD', 'ParameterValue': elasticsearch_password},
                            {'ParameterKey': 'ElasticSearchDeploymentID', 'ParameterValue': elasticsearch_deploymentid},
                            {'ParameterKey': 'DeploymentVersion', 'ParameterValue': elasticsearch_deploymentversion},
                        ],
                        Capabilities=['CAPABILITY_NAMED_IAM']  # Add capabilities if needed
                    )
                    print(f"Stack {stack_name} creation initiated. Stack ID: {response['StackId']}")
                except botocore.exceptions.ClientError as e:
                    print(f"Error deploying CloudFormation Template: {e}")
                    # Send a failure response with the error reason
                    cfnresponse.send(event, context, cfnresponse.FAILED, responseData, reason=str(e))
    
                print("CloudFormation Template deployed successfully.")
                cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData)        
      Timeout: 900
      Environment:
        Variables:
          AMIID: 
            !FindInMap 
              - AMIID
              - !Ref 'AWS::Region'
              - ami
          REGION: !Sub ${AWS::Region}
          KibanaURL: !Ref KibanaURL
          ELASTICSEARCHUSERNAME: !Ref ElasticsearchUsername
          ELASTICSEARCHPASSWORD: !Ref ElasticsearchPassword
          ElasticSearchDeploymentID: !Ref ElasticSearchDeploymentID
          DeploymentVersion: !Ref DeploymentVersion
          
  TriggersElasticAgentLambdaFunction:
    Type: 'Custom::RunCode'
    Condition: ShouldIngestEC2InstanceLogs
    DeletionPolicy: Retain
    DependsOn: ElasticAgentLambdaFunction
    Properties:
      ServiceToken: !GetAtt ElasticAgentLambdaFunction.Arn